{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda_dir\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.06\n",
      "step 100, training accuracy 0.86\n",
      "step 200, training accuracy 0.88\n",
      "step 300, training accuracy 0.96\n",
      "step 400, training accuracy 0.9\n",
      "step 500, training accuracy 0.96\n",
      "step 600, training accuracy 0.9\n",
      "step 700, training accuracy 0.98\n",
      "step 800, training accuracy 1\n",
      "step 900, training accuracy 0.96\n",
      "step 1000, training accuracy 1\n",
      "step 1100, training accuracy 0.98\n",
      "step 1200, training accuracy 1\n",
      "step 1300, training accuracy 0.98\n",
      "step 1400, training accuracy 0.96\n",
      "step 1500, training accuracy 1\n",
      "step 1600, training accuracy 0.98\n",
      "step 1700, training accuracy 0.94\n",
      "step 1800, training accuracy 1\n",
      "step 1900, training accuracy 0.96\n",
      "step 2000, training accuracy 0.98\n",
      "step 2100, training accuracy 0.98\n",
      "step 2200, training accuracy 0.96\n",
      "step 2300, training accuracy 0.98\n",
      "step 2400, training accuracy 1\n",
      "step 2500, training accuracy 0.96\n",
      "step 2600, training accuracy 0.98\n",
      "step 2700, training accuracy 1\n",
      "step 2800, training accuracy 0.98\n",
      "step 2900, training accuracy 0.98\n",
      "step 3000, training accuracy 1\n",
      "step 3100, training accuracy 0.94\n",
      "step 3200, training accuracy 0.96\n",
      "step 3300, training accuracy 1\n",
      "step 3400, training accuracy 0.96\n",
      "step 3500, training accuracy 0.96\n",
      "step 3600, training accuracy 1\n",
      "step 3700, training accuracy 0.98\n",
      "step 3800, training accuracy 0.98\n",
      "step 3900, training accuracy 1\n",
      "step 4000, training accuracy 0.98\n",
      "step 4100, training accuracy 0.98\n",
      "step 4200, training accuracy 0.96\n",
      "step 4300, training accuracy 0.98\n",
      "step 4400, training accuracy 1\n",
      "step 4500, training accuracy 1\n",
      "step 4600, training accuracy 0.98\n",
      "step 4700, training accuracy 1\n",
      "step 4800, training accuracy 1\n",
      "step 4900, training accuracy 1\n",
      "step 5000, training accuracy 0.96\n",
      "step 5100, training accuracy 1\n",
      "step 5200, training accuracy 1\n",
      "step 5300, training accuracy 1\n",
      "step 5400, training accuracy 1\n",
      "step 5500, training accuracy 1\n",
      "step 5600, training accuracy 1\n",
      "step 5700, training accuracy 0.98\n",
      "step 5800, training accuracy 1\n",
      "step 5900, training accuracy 0.98\n",
      "step 6000, training accuracy 1\n",
      "step 6100, training accuracy 0.98\n",
      "step 6200, training accuracy 1\n",
      "step 6300, training accuracy 0.96\n",
      "step 6400, training accuracy 0.98\n",
      "step 6500, training accuracy 1\n",
      "step 6600, training accuracy 1\n",
      "step 6700, training accuracy 0.98\n",
      "step 6800, training accuracy 1\n",
      "step 6900, training accuracy 1\n",
      "step 7000, training accuracy 1\n",
      "step 7100, training accuracy 0.98\n",
      "step 7200, training accuracy 0.98\n",
      "step 7300, training accuracy 0.98\n",
      "step 7400, training accuracy 1\n",
      "step 7500, training accuracy 1\n",
      "step 7600, training accuracy 0.98\n",
      "step 7700, training accuracy 1\n",
      "step 7800, training accuracy 1\n",
      "step 7900, training accuracy 1\n",
      "step 8000, training accuracy 1\n",
      "step 8100, training accuracy 0.98\n",
      "step 8200, training accuracy 1\n",
      "step 8300, training accuracy 1\n",
      "step 8400, training accuracy 1\n",
      "step 8500, training accuracy 0.98\n",
      "step 8600, training accuracy 0.98\n",
      "step 8700, training accuracy 0.98\n",
      "step 8800, training accuracy 1\n",
      "step 8900, training accuracy 1\n",
      "step 9000, training accuracy 0.98\n",
      "step 9100, training accuracy 1\n",
      "step 9200, training accuracy 1\n",
      "step 9300, training accuracy 1\n",
      "step 9400, training accuracy 0.98\n",
      "step 9500, training accuracy 1\n",
      "step 9600, training accuracy 1\n",
      "step 9700, training accuracy 1\n",
      "step 9800, training accuracy 1\n",
      "step 9900, training accuracy 0.98\n",
      "step 10000, training accuracy 1\n",
      "step 10100, training accuracy 1\n",
      "step 10200, training accuracy 1\n",
      "step 10300, training accuracy 0.98\n",
      "step 10400, training accuracy 1\n",
      "step 10500, training accuracy 1\n",
      "step 10600, training accuracy 1\n",
      "step 10700, training accuracy 1\n",
      "step 10800, training accuracy 1\n",
      "step 10900, training accuracy 1\n",
      "step 11000, training accuracy 1\n",
      "step 11100, training accuracy 1\n",
      "step 11200, training accuracy 1\n",
      "step 11300, training accuracy 1\n",
      "step 11400, training accuracy 1\n",
      "step 11500, training accuracy 1\n",
      "step 11600, training accuracy 1\n",
      "step 11700, training accuracy 1\n",
      "step 11800, training accuracy 1\n",
      "step 11900, training accuracy 1\n",
      "step 12000, training accuracy 1\n",
      "step 12100, training accuracy 1\n",
      "step 12200, training accuracy 0.98\n",
      "step 12300, training accuracy 1\n",
      "step 12400, training accuracy 1\n",
      "step 12500, training accuracy 1\n",
      "step 12600, training accuracy 1\n",
      "step 12700, training accuracy 1\n",
      "step 12800, training accuracy 1\n",
      "step 12900, training accuracy 1\n",
      "step 13000, training accuracy 1\n",
      "step 13100, training accuracy 1\n",
      "step 13200, training accuracy 1\n",
      "step 13300, training accuracy 1\n",
      "step 13400, training accuracy 1\n",
      "step 13500, training accuracy 1\n",
      "step 13600, training accuracy 1\n",
      "step 13700, training accuracy 1\n",
      "step 13800, training accuracy 1\n",
      "step 13900, training accuracy 0.98\n",
      "step 14000, training accuracy 1\n",
      "step 14100, training accuracy 1\n",
      "step 14200, training accuracy 1\n",
      "step 14300, training accuracy 1\n",
      "step 14400, training accuracy 1\n",
      "step 14500, training accuracy 0.98\n",
      "step 14600, training accuracy 1\n",
      "step 14700, training accuracy 1\n",
      "step 14800, training accuracy 1\n",
      "step 14900, training accuracy 1\n",
      "step 15000, training accuracy 1\n",
      "step 15100, training accuracy 1\n",
      "step 15200, training accuracy 1\n",
      "step 15300, training accuracy 1\n",
      "step 15400, training accuracy 1\n",
      "step 15500, training accuracy 1\n",
      "step 15600, training accuracy 1\n",
      "step 15700, training accuracy 1\n",
      "step 15800, training accuracy 1\n",
      "step 15900, training accuracy 1\n",
      "step 16000, training accuracy 1\n",
      "step 16100, training accuracy 1\n",
      "step 16200, training accuracy 1\n",
      "step 16300, training accuracy 0.98\n",
      "step 16400, training accuracy 1\n",
      "step 16500, training accuracy 1\n",
      "step 16600, training accuracy 1\n",
      "step 16700, training accuracy 1\n",
      "step 16800, training accuracy 1\n",
      "step 16900, training accuracy 1\n",
      "step 17000, training accuracy 1\n",
      "step 17100, training accuracy 1\n",
      "step 17200, training accuracy 1\n",
      "step 17300, training accuracy 0.98\n",
      "step 17400, training accuracy 1\n",
      "step 17500, training accuracy 0.98\n",
      "step 17600, training accuracy 1\n",
      "step 17700, training accuracy 1\n",
      "step 17800, training accuracy 1\n",
      "step 17900, training accuracy 1\n",
      "step 18000, training accuracy 1\n",
      "step 18100, training accuracy 1\n",
      "step 18200, training accuracy 1\n",
      "step 18300, training accuracy 1\n",
      "step 18400, training accuracy 0.98\n",
      "step 18500, training accuracy 0.98\n",
      "step 18600, training accuracy 1\n",
      "step 18700, training accuracy 1\n",
      "step 18800, training accuracy 1\n",
      "step 18900, training accuracy 1\n",
      "step 19000, training accuracy 1\n",
      "step 19100, training accuracy 1\n",
      "step 19200, training accuracy 1\n",
      "step 19300, training accuracy 1\n",
      "step 19400, training accuracy 1\n",
      "step 19500, training accuracy 1\n",
      "step 19600, training accuracy 1\n",
      "step 19700, training accuracy 1\n",
      "step 19800, training accuracy 1\n",
      "step 19900, training accuracy 1\n",
      "cf accuracy 0.9928\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "# 创建一个交互式的Session。\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 创建两个占位符，数据类型是float。x占位符的形状是[None，784]，即用来存放图像数据的变量，图像有多少张\n",
    "# 是不关注的。但是图像的数据维度有784围。怎么来的，因为MNIST处理的图片都是28*28的大小，将一个二维图像\n",
    "# 展平后，放入一个长度为784的数组中。\n",
    "# y_占位符的形状类似x，只是维度只有10，因为输出结果是0-9的数字，所以只有10种结构。\n",
    "x = tf.placeholder(\"float\", shape=[None, 784])\n",
    "y_ = tf.placeholder(\"float\", shape=[None, 10])\n",
    "\n",
    "\n",
    "# 通过函数的形式定义权重变量。变量的初始值，来自于截取正态分布中的数据。\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "\n",
    "# 通过函数的形式定义偏置量变量，偏置的初始值都是0.1，形状由shape定义。\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "\n",
    "# 定义卷积函数，其中x是输入，W是权重，也可以理解成卷积核，strides表示步长，或者说是滑动速率，包含长宽方向\n",
    "# 的步长。padding表示补齐数据。 目前有两种补齐方式，一种是SAME，表示补齐操作后（在原始图像周围补充0），实\n",
    "# 际卷积中，参与计算的原始图像数据都会参与。一种是VALID，补齐操作后，进行卷积过程中，原始图片中右边或者底部\n",
    "# 的像素数据可能出现丢弃的情况。\n",
    "def conv2d(x, w):\n",
    "  return tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# 这步定义函数进行池化操作，在卷积运算中，是一种数据下采样的操作，降低数据量，聚类数据的有效手段。常见的\n",
    "# 池化操作包含最大值池化和均值池化。这里的2*2池化，就是每4个值中取一个，池化操作的数据区域边缘不重叠。\n",
    "# 函数原型：def max_pool(value, ksize, strides, padding, data_format=\"NHWC\", name=None)。对ksize和strides\n",
    "# 定义的理解要基于data_format进行。默认NHWC，表示4维数据，[batch,height,width,channels]. 下面函数中的ksize，\n",
    "# strides中，每次处理都是一张图片，对应的处理数据是一个通道（例如，只是黑白图片）。长宽都是2，表明是2*2的\n",
    "# 池化区域，也反应出下采样的速度。\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# 定义第一层卷积核。shape在这里，对应卷积核filter。\n",
    "# 其中filter的结构为：[filter_height, filter_width, in_channels, out_channels]。这里，卷积核的高和宽都是5，\n",
    "# 输入通道1，输出通道数为32，也就是说，有32个卷积核参与卷积。\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "# 偏置量定义，偏置的维度是32.\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# 将输入tensor进行形状调整，调整成为一个28*28的图片，因为输入的时候x是一个[None,784]，有与reshape的输入项shape\n",
    "# 是[-1,28,28,1]，后续三个维度数据28,28,1相乘后得到784，所以，-1值在reshape函数中的特殊含义就可以映射程None。即\n",
    "# 输入图片的数量batch。\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "# 将2维卷积的值加上一个偏置后的tensor，进行relu操作，一种激活函数，关于激活函数，有很多内容需要研究，在此不表。\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "# 对激活函数返回结果进行下采样池化操作。\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# 第二层卷积，卷积核大小5*5，输入通道有32个，输出通道有64个，从输出通道数看，第二层的卷积单元有64个。\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "# 第二层卷积：激活和池化（类似第一层卷积操作的激活和池化）\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# 图片尺寸减小到7x7，加入一个有1024个神经元的全连接层，用于处理整个图片。把池化层输出的张量reshape成一些\n",
    "# 向量，乘上权重矩阵，加上偏置，然后对其使用ReLU激活操作。\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "# 将第二层池化后的数据进行变形\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "# 进行矩阵乘，加偏置后进行relu激活\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "# 对第二层卷积经过relu后的结果，基于tensor值keep_prob进行保留或者丢弃相关维度上的数据。这个是为了防止过拟合，快速收敛。\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "# 最后，添加一个softmax层，就像前面的单层softmax regression一样。softmax是一个多选择分类函数，其作用和sigmoid这个2值\n",
    "# 分类作用地位一样，在我们这个例子里面，softmax输出是10个。\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "# 实际值y_与预测值y_conv的自然对数求乘积，在对应的维度上上求和，该值作为梯度下降法的输入\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "\n",
    "# 下面基于步长1e-4来求梯度，梯度下降方法为AdamOptimizer。\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# 首先分别在训练值y_conv以及实际标签值y_的第一个轴向取最大值，比较是否相等\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "\n",
    "# 对correct_prediction值进行浮点化转换，然后求均值，得到精度。\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "# 先通过tf执行全局变量的初始化，然后启用session运行图。\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "  # 从mnist的train数据集中取出50批数据，返回的batch其实是一个列表，元素0表示图像数据，元素1表示标签值\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i % 100 == 0:\n",
    "    # 计算精度，通过所取的batch中的图像数据以及标签值还有dropout参数，带入到accuracy定义时所涉及到的相关变量中，进行\n",
    "    # session的运算，得到一个输出，也就是通过已知的训练图片数据和标签值进行似然估计，然后基于梯度下降，进行权值训练。\n",
    "    train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  # 此步主要是用来训练W和bias用的。基于似然估计函数进行梯度下降，收敛后，就等于W和bias都训练好了。\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "# 对测试图片和测试标签值以及给定的keep_prob进行feed操作，进行计算求出识别率。就相当于前面训练好的W和bias作为已知参数。\n",
    "print(\"cf accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [6]\n",
      "Prediction: [6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# last,Get one and predict\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label:\", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "print(\"Prediction:\", sess.run(tf.argmax(y_conv, 1),feed_dict={x: mnist.test.images[r:r + 1],keep_prob:1}))\n",
    "plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
